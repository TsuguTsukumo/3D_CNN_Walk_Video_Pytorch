{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# sys.path.append('/workspace/Walk_Video_PyTorch/project')\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torchvision.io import read_video, write_video\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_path = '/workspace/data/dataset/train/ASD'\n",
    "sample_path_1 = '20170612_1_ASD_lat__V1-0005.mp4'\n",
    "\n",
    "sample_path_2 = '20170619_2_ASD_lat__V1-0006.mp4'\n",
    "sample_path_3 = '20170313_ASD_lat_ (1).mp4'\n",
    "sample_path_4 = '20170328_ASD_lat_ (2).mp4'\n",
    "\n",
    "sample_path_5 = '20170313_ASD_lat_V1-0002.mp4'\n",
    "\n",
    "video, _, _ = read_video(os.path.join(prefix_path, sample_path_5), pts_unit='sec') # t,h,w,c\n",
    "\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.functional.(video[100][500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_detection import batch_detection\n",
    "\n",
    "get_bbox = batch_detection(img_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list, box_list, pred_list, center_point = get_bbox.get_frame_box(inp_imgs=video[:, :, :, :]) # t, h, w, c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list[0].shape, box_list[0], pred_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_list, center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(512, 512))\n",
    "\n",
    "# drawn_boxes_list = []\n",
    "\n",
    "# for num in range(len(frame_list)):\n",
    "\n",
    "#     drawn_boxes = draw_bounding_boxes(frame_list[num].permute(2, 0, 1), box_list[num], colors=\"red\")\n",
    "\n",
    "#     drawn_boxes_list.append(drawn_boxes)\n",
    "#     plt.subplot(len(frame_list), 1, num+1)\n",
    "#     plt.imshow(drawn_boxes.permute(1, 2, 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_list, box_list, pred_list, center_point = get_bbox.get_frame_box(inp_imgs=video[:, :, :, :]) # t, h, w, c\n",
    "\n",
    "one_batch = get_bbox.handel_batch_imgs(video_frame=video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(filename='output.mp4', video_array=one_batch.permute(1, 2, 3, 0), fps=30) # (c, t, h, w) to (t, h, w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(512, 512))\n",
    "\n",
    "v = Visualizer(frame_list[-19], instance_mode=ColorMode(1), scale=1.0)\n",
    "\n",
    "out = v.draw_instance_predictions(pred_list[-19])\n",
    "\n",
    "plt.imshow(out.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.transforms.functional import (\n",
    "    uniform_temporal_subsample,\n",
    "    short_side_scale_with_boxes,\n",
    "    clip_boxes_to_image,\n",
    "    uniform_crop_with_boxes,\n",
    "    random_crop_with_boxes,\n",
    ")\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "encoded_vid = EncodedVideo.from_path(os.path.join(prefix_path, sample_path_5))\n",
    "print('Completed loading encoded video.')\n",
    "video = encoded_vid.get_clip(0, 1)['video']\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(512, 512))\n",
    "\n",
    "c, t, h, w = video.shape \n",
    "\n",
    "for num in range(t):\n",
    "\n",
    "    plt.subplot(t, 1, num+1)\n",
    "    plt.imshow(video.permute(1, 2, 3, 0)[num] / 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch = uniform_temporal_subsample(video, 5)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(512, 512))\n",
    "\n",
    "c, t, h, w = batch.shape \n",
    "\n",
    "for num in range(t):\n",
    "\n",
    "    plt.subplot(1, t, num+1)\n",
    "    plt.imshow(batch.permute(1, 2, 3, 0)[num] / 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(512, 512))\n",
    "\n",
    "# for num in range(len(frame_list)):\n",
    "\n",
    "#     # v = Visualizer(frame_list[num], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "#     v = Visualizer(frame_list[num], instance_mode=ColorMode(1), scale=1.0)\n",
    "\n",
    "#     out = v.draw_instance_predictions(pred_list[num])\n",
    "\n",
    "#     plt.subplot(len(frame_list), 1, num+1) \n",
    "\n",
    "#     plt.imshow(out.get_image())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
