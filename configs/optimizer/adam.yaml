adam:
  lr: 0.0001 # learning rate for optimizer
  beta1: 0.5
  beta2: 0.999